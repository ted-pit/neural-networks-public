{"cells":[{"cell_type":"markdown","metadata":{"id":"1x7mjzUHDtvx"},"source":["# Classification\n","\n","Classification is supervised learning with categorical labels. You are given labeled data consisting of features and labels $\\{\\vec{x}_i, \\vec{y}_i\\}$, where $\\vec{y}_i$ is a vector of binary values indicating class membership. An example of $\\vec{y}_i$ that indicates membership of classes \"soluble in THF\", \"insoluble in water\", \"soluble in chloroform\" might be:\n","\n","|  THF  | water | chloroform |\n","|:------|:-----:| ----------:|\n","|   1   |   0   |   1        |\n","\n","where we've indicated that the molecule in soluble in THF and chloroform but not water. As a vector, it is $\\vec{y} = (1, 0, 1) $.  This is the general format of classification and can be called **multi-label** classification because we are attaching three labels: THF soluble, water insoluble, chloroform soluble. This can be restricted so that each data point belongs to only one class -- called **multi-class** classification. This might be like assigning visible color. A molecule can only be red or green or orange, but not multiple colors. Finally, you can only have one class and a label can only belong to the single class or does not belong to the single class. This is called **binary** classification and is the most common classification type. If you're doing multi-label or multi-class classification, the shape of $\\vec{y}$ will be a vector length $K$ where $K$ indicates number of classes. In the case of binary classification, the label is a binary value of 1 or 0 where 1 means it is a member of the class. You can view this as there being two classes: a **positive** class ($y = 1$) and **negative** class ($y = 0$). For example, you could be predicting if a molecule will kill cells. If the molecule is in the positive class, it kills cells. If it is the negative class, it is inert and does not kill cells. Depending on your choice of model type, when you predict the labels ($\\hat{\\vec{y}}$), your model could predict probabilities. \n","\n","```{admonition} Audience & Objectives\n","This chapter builds on {doc}`regression` and a basic knowledge of probability theory -- specifically random variables, normalization, and the metrics section below touches on calibration (empirical agreement of model distribution with true distribution). You can read [my notes](https://raw.githubusercontent.com/whitead/numerical_stats/master/unit_2/lectures/lecture_3.pdf) or any introductory probability text to learn these topics. After completing this chapter, you should be able to: \n","\n","  * Distinguish between types of classification\n","  * Set-up and train a classifier with a cross-entropy loss function\n","  * Characterize classifier performance\n","  * Identify and address class imbalance\n","```\n","\n","\n","\n","```{margin}\n","Note that in multi-class and binary classification $\\sum \\hat{\\vec{y}} = 1$, but \n","in multi-label classification this is not the case. Multi-label classification is like doing $K$ instances of binary classification. \n","```\n","\n","The goal of classification is to find a function that describes the relationship between features and class, $\\hat{f}(\\vec{x}) = \\hat{y}$. We'll see that this problem can be converted to regression by using probability or *distance from  a decision boundary*. This means much of what we learned previously can be applied to this classification.\n","\n","The classic application of classification in structure-activity relationship is in drug discovery, where we want to predict if a molecule will be active (positive class) as a function of structure. That dates back to the 1970s. Classification is widely used now in materials and chemistry. Many molecular design problems can be formulated as classification. For example, you can use it to design new organic photovoltaic materials {cite}`sun2019machine` or antimicrobial peptides {cite}`barrett2018classifying`."]},{"cell_type":"markdown","metadata":{"id":"HN3F0TXYDtv2"},"source":["## Data\n","\n","The dataset for this lecture was prepared by the MoleculeNet group {cite}`wu2018moleculenet`.  It is a collection of molecules that succeeded or failed in clinical trials. The development of a new drug can cost well over a $1 billion, so any way to predict if a molecule will fail during clinical trials is highly valuable. The reason molecules fail in clinical trials is often due to safety, so even though some of these drugs failed because they were not effective there may be something common to each of the failed ones that we can learn.\n","\n","The labels will be the FDA_Approved column which is a 1 or 0 indicating FDA approval status. This is an example of binary classification."]},{"cell_type":"markdown","metadata":{"id":"y78vGacyDtv2"},"source":["## Running This Notebook\n","\n","\n","Click the &nbsp;<i aria-label=\"Launch interactive content\" class=\"fas fa-rocket\"></i>&nbsp; above to launch this page as an interactive Google Colab. See details below on installing packages.\n","\n","````{tip} My title\n",":class: dropdown\n","To install packages, execute this code in a new cell. \n","\n","```\n","!pip install dmol-book\n","```\n","\n","If you find install problems, you can get the latest working versions of packages used in [this book here](https://github.com/whitead/dmol-book/blob/master/package/setup.py)\n","\n","````"]},{"cell_type":"code","source":["!pip install dmol-book"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cUruiz9SU5UV","executionInfo":{"status":"ok","timestamp":1666805323823,"user_tz":-60,"elapsed":197634,"user":{"displayName":"Ted Pitman","userId":"14049291477165845436"}},"outputId":"fdceaaf8-8e1d-4688-dccb-2338123329c8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting dmol-book\n","  Downloading dmol_book-1.2.0-py3-none-any.whl (2.4 kB)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (from dmol-book) (0.3.22+cuda11.cudnn805)\n","Collecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Collecting selfies\n","  Downloading selfies-2.1.1-py3-none-any.whl (35 kB)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from dmol-book) (1.7.1)\n","Collecting simpletransformers==0.63.9\n","  Downloading simpletransformers-0.63.9-py3-none-any.whl (250 kB)\n","\u001b[K     |████████████████████████████████| 250 kB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from dmol-book) (0.2.3.5)\n","Collecting rdkit>=2022\n","  Downloading rdkit-2022.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.5 MB)\n","\u001b[K     |████████████████████████████████| 29.5 MB 2.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dmol-book) (1.21.6)\n","Collecting tensorflowjs\n","  Downloading tensorflowjs-4.0.0-py3-none-any.whl (83 kB)\n","\u001b[K     |████████████████████████████████| 83 kB 1.1 MB/s \n","\u001b[?25hCollecting jupyter-book==0.12.3\n","  Downloading jupyter_book-0.12.3-py3-none-any.whl (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n","\u001b[?25hCollecting mordred[full]\n","  Downloading mordred-1.2.0.tar.gz (128 kB)\n","\u001b[K     |████████████████████████████████| 128 kB 41.8 MB/s \n","\u001b[?25hCollecting pillow>=8.3.2\n","  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 39.2 MB/s \n","\u001b[?25hCollecting MDAnalysis\n","  Downloading MDAnalysis-2.1.0.tar.gz (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 16.5 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting dm-haiku\n","  Downloading dm_haiku-0.0.8-py3-none-any.whl (350 kB)\n","\u001b[K     |████████████████████████████████| 350 kB 56.8 MB/s \n","\u001b[?25hCollecting emlp==1.0.2\n","  Downloading emlp-1.0.2-py3-none-any.whl (47 kB)\n","\u001b[K     |████████████████████████████████| 47 kB 4.7 MB/s \n","\u001b[?25hCollecting e3nn\n","  Downloading e3nn-0.5.0-py3-none-any.whl (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 25.2 MB/s \n","\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from dmol-book) (0.11.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from dmol-book) (1.3.5)\n","Requirement already satisfied: tensorflow>=2.7 in /usr/local/lib/python3.7/dist-packages (from dmol-book) (2.9.2)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from dmol-book) (1.3.0)\n","Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (from dmol-book) (0.3.23)\n","Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from dmol-book) (0.16.0)\n","Collecting exmol\n","  Downloading exmol-2.1.1-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 34.6 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from dmol-book) (3.2.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from dmol-book) (0.8.10)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from dmol-book) (2.6.3)\n","Requirement already satisfied: tqdm>=4.38 in /usr/local/lib/python3.7/dist-packages (from emlp==1.0.2->dmol-book) (4.64.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from emlp==1.0.2->dmol-book) (3.1.0)\n","Collecting objax\n","  Downloading objax-1.6.0.tar.gz (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 4.6 MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from emlp==1.0.2->dmol-book) (3.6.4)\n","Collecting plum-dispatch\n","  Downloading plum_dispatch-1.7.4-py3-none-any.whl (24 kB)\n","Collecting optax\n","  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 51.3 MB/s \n","\u001b[?25hCollecting sphinx-comments\n","  Downloading sphinx_comments-0.0.3-py3-none-any.whl (4.6 kB)\n","Collecting sphinx-panels~=0.6.0\n","  Downloading sphinx_panels-0.6.0-py3-none-any.whl (87 kB)\n","\u001b[K     |████████████████████████████████| 87 kB 6.0 MB/s \n","\u001b[?25hCollecting myst-nb~=0.13.1\n","  Downloading myst_nb-0.13.2-py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 32 kB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from jupyter-book==0.12.3->dmol-book) (6.0)\n","Collecting sphinx_book_theme~=0.1.4\n","  Downloading sphinx_book_theme-0.1.10-py3-none-any.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.1 MB/s \n","\u001b[?25hCollecting sphinx-copybutton\n","  Downloading sphinx_copybutton-0.5.0-py3-none-any.whl (12 kB)\n","Collecting sphinxcontrib-bibtex<=2.5.0,>=2.2.0\n","  Downloading sphinxcontrib_bibtex-2.5.0-py3-none-any.whl (39 kB)\n","Collecting jsonschema<4\n","  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n","\u001b[K     |████████████████████████████████| 56 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: Jinja2<3.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-book==0.12.3->dmol-book) (2.11.3)\n","Collecting sphinx-jupyterbook-latex~=0.4.6\n","  Downloading sphinx_jupyterbook_latex-0.4.7-py3-none-any.whl (13 kB)\n","Collecting sphinx<5,>=3\n","  Downloading Sphinx-4.5.0-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 34.7 MB/s \n","\u001b[?25hCollecting linkify-it-py~=1.0.1\n","  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n","Requirement already satisfied: docutils<0.18,>=0.15 in /usr/local/lib/python3.7/dist-packages (from jupyter-book==0.12.3->dmol-book) (0.17.1)\n","Collecting sphinx-thebe~=0.1.1\n","  Downloading sphinx_thebe-0.1.2-py3-none-any.whl (8.3 kB)\n","Requirement already satisfied: click<9,>=7.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-book==0.12.3->dmol-book) (7.1.2)\n","Collecting sphinx-external-toc~=0.2.3\n","  Downloading sphinx_external_toc-0.2.4-py3-none-any.whl (25 kB)\n","Collecting sphinx_togglebutton\n","  Downloading sphinx_togglebutton-0.3.2-py3-none-any.whl (8.2 kB)\n","Collecting sphinx-multitoc-numbering~=0.1.3\n","  Downloading sphinx_multitoc_numbering-0.1.3-py3-none-any.whl (4.6 kB)\n","Collecting streamlit\n","  Downloading streamlit-1.13.0-py2.py3-none-any.whl (9.2 MB)\n","\u001b[K     |████████████████████████████████| 9.2 MB 40.4 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from simpletransformers==0.63.9->dmol-book) (1.7.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from simpletransformers==0.63.9->dmol-book) (2.23.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from simpletransformers==0.63.9->dmol-book) (1.0.2)\n","Collecting datasets\n","  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n","\u001b[K     |████████████████████████████████| 441 kB 41.5 MB/s \n","\u001b[?25hCollecting wandb>=0.10.32\n","  Downloading wandb-0.13.4-py2.py3-none-any.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 33.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from simpletransformers==0.63.9->dmol-book) (2022.6.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from simpletransformers==0.63.9->dmol-book) (2.9.1)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 45.7 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n","\u001b[?25hCollecting transformers>=4.6.0\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 42.4 MB/s \n","\u001b[?25hCollecting tokenizers\n","  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 45.6 MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.1->jupyter-book==0.12.3->dmol-book) (2.0.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema<4->jupyter-book==0.12.3->dmol-book) (57.4.0)\n","Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4->jupyter-book==0.12.3->dmol-book) (1.15.0)\n","Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4->jupyter-book==0.12.3->dmol-book) (0.18.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema<4->jupyter-book==0.12.3->dmol-book) (4.13.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4->jupyter-book==0.12.3->dmol-book) (22.1.0)\n","Collecting uc-micro-py\n","  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n","Requirement already satisfied: ipywidgets<8,>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (7.7.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (7.9.0)\n","Collecting jupyter-sphinx~=0.3.2\n","  Downloading jupyter_sphinx-0.3.2-py3-none-any.whl (20 kB)\n","Requirement already satisfied: nbformat~=5.0 in /usr/local/lib/python3.7/dist-packages (from myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (5.7.0)\n","Collecting myst-parser~=0.15.2\n","  Downloading myst_parser-0.15.2-py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: nbconvert<7,>=5.6 in /usr/local/lib/python3.7/dist-packages (from myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (5.6.1)\n","Collecting jupyter-cache~=0.4.1\n","  Downloading jupyter_cache-0.4.3-py3-none-any.whl (31 kB)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (5.1.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (3.6.1)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.2.0)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (5.3.4)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (3.0.3)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (5.1.1)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (2.0.10)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.7.5)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 40.3 MB/s \n","\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (2.6.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.2.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (4.4.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.8.3)\n","Requirement already satisfied: sqlalchemy<1.5,>=1.3.12 in /usr/local/lib/python3.7/dist-packages (from jupyter-cache~=0.4.1->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (1.4.42)\n","Collecting nbclient<0.6,>=0.2\n","  Downloading nbclient-0.5.13-py3-none-any.whl (70 kB)\n","\u001b[K     |████████████████████████████████| 70 kB 7.8 MB/s \n","\u001b[?25hCollecting nbdime\n","  Downloading nbdime-3.1.1-py2.py3-none-any.whl (5.3 MB)\n","\u001b[K     |████████████████████████████████| 5.3 MB 43.8 MB/s \n","\u001b[?25hCollecting markdown-it-py<2.0.0,>=1.0.0\n","  Downloading markdown_it_py-1.1.0-py3-none-any.whl (83 kB)\n","\u001b[K     |████████████████████████████████| 83 kB 1.7 MB/s \n","\u001b[?25hCollecting mdit-py-plugins~=0.2.8\n","  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 32 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py<2.0.0,>=1.0.0->myst-parser~=0.15.2->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (4.1.1)\n","Collecting attrs>=17.4.0\n","  Downloading attrs-21.4.0-py2.py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 6.7 MB/s \n","\u001b[?25hCollecting nest-asyncio\n","  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (4.11.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (23.2.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (2.8.2)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<7,>=5.6->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.8.4)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<7,>=5.6->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<7,>=5.6->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<7,>=5.6->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (5.0.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<7,>=5.6->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.6.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<7,>=5.6->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (1.5.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat~=5.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (2.16.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema<4->jupyter-book==0.12.3->dmol-book) (3.9.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.2.5)\n","Collecting sphinxcontrib-devhelp\n","  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 3.4 MB/s \n","\u001b[?25hRequirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx<5,>=3->jupyter-book==0.12.3->dmol-book) (1.4.1)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from sphinx<5,>=3->jupyter-book==0.12.3->dmol-book) (1.1.5)\n","Collecting sphinxcontrib-htmlhelp>=2.0.0\n","  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n","\u001b[K     |████████████████████████████████| 100 kB 9.7 MB/s \n","\u001b[?25hCollecting sphinxcontrib-applehelp\n","  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n","\u001b[K     |████████████████████████████████| 121 kB 45.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx<5,>=3->jupyter-book==0.12.3->dmol-book) (21.3)\n","Collecting sphinxcontrib-jsmath\n","  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx<5,>=3->jupyter-book==0.12.3->dmol-book) (2.2.0)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx<5,>=3->jupyter-book==0.12.3->dmol-book) (0.7.12)\n","Collecting sphinxcontrib-qthelp\n","  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 9.3 MB/s \n","\u001b[?25hRequirement already satisfied: babel>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx<5,>=3->jupyter-book==0.12.3->dmol-book) (2.10.3)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel>=1.3->sphinx<5,>=3->jupyter-book==0.12.3->dmol-book) (2022.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers==0.63.9->dmol-book) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers==0.63.9->dmol-book) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers==0.63.9->dmol-book) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->simpletransformers==0.63.9->dmol-book) (2.10)\n","Collecting pydata-sphinx-theme~=0.7.2\n","  Downloading pydata_sphinx_theme-0.7.2-py3-none-any.whl (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 57.4 MB/s \n","\u001b[?25hRequirement already satisfied: beautifulsoup4<5,>=4.6.1 in /usr/local/lib/python3.7/dist-packages (from sphinx_book_theme~=0.1.4->jupyter-book==0.12.3->dmol-book) (4.6.3)\n","Collecting docutils<0.18,>=0.15\n","  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n","\u001b[K     |████████████████████████████████| 548 kB 51.4 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from sphinx-jupyterbook-latex~=0.4.6->jupyter-book==0.12.3->dmol-book) (5.10.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from sphinx_togglebutton->jupyter-book==0.12.3->dmol-book) (0.37.1)\n","Collecting pybtex-docutils>=1.0.0\n","  Downloading pybtex_docutils-1.0.2-py3-none-any.whl (6.3 kB)\n","Collecting pybtex>=0.24\n","  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n","\u001b[K     |████████████████████████████████| 561 kB 52.0 MB/s \n","\u001b[?25hCollecting latexcodec>=1.0.4\n","  Downloading latexcodec-2.0.1-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy<1.5,>=1.3.12->jupyter-cache~=0.4.1->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (1.1.3.post0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (1.6.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (0.4.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (14.0.6)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (0.27.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (3.3.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (3.17.3)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (1.12)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (1.50.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (1.14.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (2.0.1)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (2.9.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (0.2.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (1.3.0)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7->dmol-book) (2.9.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->emlp==1.0.2->dmol-book) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers==0.63.9->dmol-book) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers==0.63.9->dmol-book) (3.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers==0.63.9->dmol-book) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers==0.63.9->dmol-book) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers==0.63.9->dmol-book) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->simpletransformers==0.63.9->dmol-book) (0.6.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers==0.63.9->dmol-book) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers==0.63.9->dmol-book) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers==0.63.9->dmol-book) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers==0.63.9->dmol-book) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers==0.63.9->dmol-book) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers==0.63.9->dmol-book) (3.2.2)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n","\u001b[K     |████████████████████████████████| 163 kB 53.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->simpletransformers==0.63.9->dmol-book) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx<5,>=3->jupyter-book==0.12.3->dmol-book) (3.0.9)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers==0.63.9->dmol-book) (2.3)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n","\u001b[K     |████████████████████████████████| 166 kB 64.9 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 51.9 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb>=0.10.32->simpletransformers==0.63.9->dmol-book) (5.4.8)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.10.0-py2.py3-none-any.whl (166 kB)\n","\u001b[K     |████████████████████████████████| 166 kB 51.9 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 45.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n","\u001b[K     |████████████████████████████████| 162 kB 61.8 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 60.6 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 55.3 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 62.4 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 63.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 38.5 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 50.7 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 48.9 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n","\u001b[K     |████████████████████████████████| 157 kB 51.1 MB/s \n","\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 50.4 MB/s \n","\u001b[?25hRequirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (5.5.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.13.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (1.8.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<8,>=7.0.0->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.7.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<7,>=5.6->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (0.5.1)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers==0.63.9->dmol-book) (0.3.5.1)\n","Collecting xxhash\n","  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 43.9 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers==0.63.9->dmol-book) (3.8.3)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 38.7 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers==0.63.9->dmol-book) (6.0.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets->simpletransformers==0.63.9->dmol-book) (2022.10.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers==0.63.9->dmol-book) (6.0.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers==0.63.9->dmol-book) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers==0.63.9->dmol-book) (1.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers==0.63.9->dmol-book) (1.8.1)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers==0.63.9->dmol-book) (0.13.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers==0.63.9->dmol-book) (1.2.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets->simpletransformers==0.63.9->dmol-book) (2.1.1)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 51.0 MB/s \n","\u001b[?25hCollecting jmp>=0.0.2\n","  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from e3nn->dmol-book) (1.12.1+cu113)\n","Collecting opt-einsum-fx>=0.1.4\n","  Downloading opt_einsum_fx-0.1.4-py3-none-any.whl (13 kB)\n","Collecting importlib-resources\n","  Downloading importlib_resources-5.6.0-py3-none-any.whl (28 kB)\n","Collecting skunk>=0.4.0\n","  Downloading skunk-0.4.0-py3-none-any.whl (5.6 kB)\n","Collecting rdkit-pypi\n","  Downloading rdkit_pypi-2022.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.5 MB)\n","\u001b[K     |████████████████████████████████| 29.5 MB 1.7 MB/s \n","\u001b[?25hCollecting ratelimit\n","  Downloading ratelimit-2.2.1.tar.gz (5.3 kB)\n","Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax->dmol-book) (0.8.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dmol-book) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dmol-book) (0.11.0)\n","Collecting GridDataFormats>=0.4.0\n","  Downloading GridDataFormats-0.7.0-py2.py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 40.4 MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from MDAnalysis->dmol-book) (1.2.0)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.7/dist-packages (from MDAnalysis->dmol-book) (3.1.0)\n","Collecting biopython>=1.71\n","  Downloading biopython-1.79-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 44.4 MB/s \n","\u001b[?25hCollecting gsd>=1.4.0\n","  Downloading gsd-2.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 60.4 MB/s \n","\u001b[?25hCollecting mmtf-python>=1.0.0\n","  Downloading mmtf_python-1.1.3-py2.py3-none-any.whl (25 kB)\n","Collecting mrcfile\n","  Downloading mrcfile-1.4.3-py2.py3-none-any.whl (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n","\u001b[?25hRequirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mmtf-python>=1.0.0->MDAnalysis->dmol-book) (1.0.4)\n","Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->dmol-book) (2.9.0)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n","\u001b[K     |████████████████████████████████| 115 kB 43.3 MB/s \n","\u001b[?25hCollecting jupyter-server\n","  Downloading jupyter_server-1.21.0-py3-none-any.whl (346 kB)\n","\u001b[K     |████████████████████████████████| 346 kB 59.2 MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting jupyter-server-mathjax>=0.2.2\n","  Downloading jupyter_server_mathjax-0.2.6-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 34.2 MB/s \n","\u001b[?25hCollecting argon2-cffi\n","  Downloading argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n","Collecting prometheus-client\n","  Downloading prometheus_client-0.15.0-py3-none-any.whl (60 kB)\n","\u001b[K     |████████████████████████████████| 60 kB 5.4 MB/s \n","\u001b[?25hCollecting websocket-client\n","  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.0 MB/s \n","\u001b[?25hCollecting anyio<4,>=3.1.0\n","  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n","\u001b[K     |████████████████████████████████| 80 kB 7.9 MB/s \n","\u001b[?25hCollecting tornado>=4.2\n","  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n","\u001b[K     |████████████████████████████████| 423 kB 42.6 MB/s \n","\u001b[?25hCollecting nbconvert<7,>=5.6\n","  Downloading nbconvert-6.5.4-py3-none-any.whl (563 kB)\n","\u001b[K     |████████████████████████████████| 563 kB 60.4 MB/s \n","\u001b[?25hCollecting sniffio>=1.1\n","  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<7,>=5.6->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (4.9.1)\n","Collecting Jinja2<3.1\n","  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 46.6 MB/s \n","\u001b[?25hCollecting tinycss2\n","  Downloading tinycss2-1.2.1-py3-none-any.whl (21 kB)\n","Collecting jupyterlab-pygments\n","  Downloading jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)\n","Collecting argon2-cffi-bindings\n","  Downloading argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server->nbdime->jupyter-cache~=0.4.1->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server->nbdime->jupyter-cache~=0.4.1->myst-nb~=0.13.1->jupyter-book==0.12.3->dmol-book) (2.21)\n","Collecting parameterized\n","  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\n","Collecting chex>=0.0.4\n","  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->emlp==1.0.2->dmol-book) (0.1.7)\n","Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->emlp==1.0.2->dmol-book) (0.12.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->emlp==1.0.2->dmol-book) (1.11.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->emlp==1.0.2->dmol-book) (0.7.1)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->emlp==1.0.2->dmol-book) (1.4.1)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->emlp==1.0.2->dmol-book) (9.0.0)\n","Collecting watchdog\n","  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 6.9 MB/s \n","\u001b[?25hCollecting pympler>=0.9\n","  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n","\u001b[K     |████████████████████████████████| 164 kB 51.6 MB/s \n","\u001b[?25hCollecting validators>=0.2\n","  Downloading validators-0.20.0.tar.gz (30 kB)\n","Collecting blinker>=1.0.0\n","  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers==0.63.9->dmol-book) (1.5.1)\n","Collecting rich>=10.11.0\n","  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n","\u001b[K     |████████████████████████████████| 237 kB 43.8 MB/s \n","\u001b[?25hCollecting semver\n","  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n","Collecting pydeck>=0.1.dev5\n","  Downloading pydeck-0.8.0b4-py2.py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 47.7 MB/s \n","\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers==0.63.9->dmol-book) (4.2.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit->simpletransformers==0.63.9->dmol-book) (0.10.2)\n","Collecting commonmark<0.10.0,>=0.9.0\n","  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->dmol-book) (1.2.1)\n","Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->dmol-book) (1.5.0)\n","Collecting flax>=0.5.3\n","  Downloading flax-0.6.1-py3-none-any.whl (185 kB)\n","\u001b[K     |████████████████████████████████| 185 kB 62.3 MB/s \n","\u001b[?25hCollecting tensorflowjs\n","  Downloading tensorflowjs-3.21.0-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 8.1 MB/s \n","\u001b[?25hCollecting packaging\n","  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n","\u001b[K     |████████████████████████████████| 40 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs->dmol-book) (0.12.0)\n","Collecting tensorflowjs\n","  Downloading tensorflowjs-3.20.0-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 5.9 MB/s \n","\u001b[?25h  Downloading tensorflowjs-3.19.0-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 5.5 MB/s \n","\u001b[?25h  Downloading tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 5.3 MB/s \n","\u001b[?25hBuilding wheels for collected packages: MDAnalysis, mordred, objax, pathtools, ratelimit, seqeval, sklearn, validators\n","  Building wheel for MDAnalysis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for MDAnalysis: filename=MDAnalysis-2.1.0-cp37-cp37m-linux_x86_64.whl size=4649779 sha256=d2cea82971941535eed71b16ef39debe9a39419a2c9b0d433dd6eec68b5fef80\n","  Stored in directory: /root/.cache/pip/wheels/fa/dd/6b/9d51e7216a401b71949467a123e3b2dffba11256346f7f7bda\n","  Building wheel for mordred (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mordred: filename=mordred-1.2.0-py3-none-any.whl size=176725 sha256=bf318d5400d100dc7bc803e28ed2bbf7d605b52ab5e4d615b87aafcb050e1135\n","  Stored in directory: /root/.cache/pip/wheels/02/c0/2e/e7e3d63b431777712ebc128bc4deb9ac5cb19afc7c1ea341ec\n","  Building wheel for objax (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for objax: filename=objax-1.6.0-py3-none-any.whl size=86415 sha256=5b6cb03ae91659b04c87417bc20a3d0322df6949b13c6a2e4a2cf0ce04e343a6\n","  Stored in directory: /root/.cache/pip/wheels/3f/22/9b/c4b9035e596d94932a13655ebe8ad1e757b700b9a5d22bdf3b\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=0f921c4523716074d4d9da5a12b7d98cb1b117fa4c293da4a26cb21922d46fa7\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","  Building wheel for ratelimit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ratelimit: filename=ratelimit-2.2.1-py3-none-any.whl size=5908 sha256=61af43c1ea9df79e52a1c3502b23704a14f3e2b79583cc7556ff1c15dfdbfd86\n","  Stored in directory: /root/.cache/pip/wheels/5d/c2/23/4915cca200175fece0d5015f1981f4e1ecb5e3ef40b66cf525\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=554fe4b3665916844f4f9878db3e6ee94d4b9559d65f3911e39d883b70914450\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=15e79f1453768d25ed587145943ca6a01f983f1380d63d217b5bb28d2217e32f\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=42471639d97f19331d9c1eec7ad17e9191a9caa81cf1e5bf2529516963d5cff7\n","  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n","Successfully built MDAnalysis mordred objax pathtools ratelimit seqeval sklearn validators\n","Installing collected packages: attrs, tornado, jsonschema, nest-asyncio, jedi, tinycss2, sniffio, packaging, nbclient, jupyterlab-pygments, Jinja2, argon2-cffi-bindings, websocket-client, urllib3, smmap, prometheus-client, nbconvert, argon2-cffi, anyio, jupyter-server, importlib-resources, gitdb, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, markdown-it-py, latexcodec, jupyter-server-mathjax, GitPython, docutils, colorama, sphinx, pybtex, nbdime, mdit-py-plugins, commonmark, xxhash, watchdog, validators, uc-micro-py, tokenizers, sphinx-togglebutton, shortuuid, setproctitle, sentry-sdk, semver, rich, responses, pympler, pydeck, pydata-sphinx-theme, pybtex-docutils, pillow, pathtools, parameterized, myst-parser, multiprocess, mrcfile, jupyter-sphinx, jupyter-cache, huggingface-hub, docker-pycreds, chex, blinker, wandb, transformers, streamlit, sphinxcontrib-bibtex, sphinx-thebe, sphinx-panels, sphinx-multitoc-numbering, sphinx-jupyterbook-latex, sphinx-external-toc, sphinx-copybutton, sphinx-comments, sphinx-book-theme, skunk, sklearn, seqeval, sentencepiece, selfies, rdkit-pypi, ratelimit, plum-dispatch, optax, opt-einsum-fx, objax, myst-nb, mordred, mmtf-python, linkify-it-py, jmp, gsd, GridDataFormats, datasets, biopython, tensorflowjs, simpletransformers, rdkit, MDAnalysis, jupyter-book, exmol, emlp, e3nn, dm-haiku, dmol-book\n","  Attempting uninstall: attrs\n","    Found existing installation: attrs 22.1.0\n","    Uninstalling attrs-22.1.0:\n","      Successfully uninstalled attrs-22.1.0\n","  Attempting uninstall: tornado\n","    Found existing installation: tornado 5.1.1\n","    Uninstalling tornado-5.1.1:\n","      Successfully uninstalled tornado-5.1.1\n","  Attempting uninstall: jsonschema\n","    Found existing installation: jsonschema 4.3.3\n","    Uninstalling jsonschema-4.3.3:\n","      Successfully uninstalled jsonschema-4.3.3\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: Jinja2\n","    Found existing installation: Jinja2 2.11.3\n","    Uninstalling Jinja2-2.11.3:\n","      Successfully uninstalled Jinja2-2.11.3\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: nbconvert\n","    Found existing installation: nbconvert 5.6.1\n","    Uninstalling nbconvert-5.6.1:\n","      Successfully uninstalled nbconvert-5.6.1\n","  Attempting uninstall: importlib-resources\n","    Found existing installation: importlib-resources 5.10.0\n","    Uninstalling importlib-resources-5.10.0:\n","      Successfully uninstalled importlib-resources-5.10.0\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.17.1\n","    Uninstalling docutils-0.17.1:\n","      Successfully uninstalled docutils-0.17.1\n","  Attempting uninstall: sphinx\n","    Found existing installation: Sphinx 1.8.6\n","    Uninstalling Sphinx-1.8.6:\n","      Successfully uninstalled Sphinx-1.8.6\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires tornado~=5.1.0, but you have tornado 6.2 which is incompatible.\n","flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.0.3 which is incompatible.\u001b[0m\n","Successfully installed GitPython-3.1.29 GridDataFormats-0.7.0 Jinja2-3.0.3 MDAnalysis-2.1.0 anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 attrs-21.4.0 biopython-1.79 blinker-1.5 chex-0.1.5 colorama-0.4.6 commonmark-0.9.1 datasets-2.6.1 dm-haiku-0.0.8 dmol-book-1.2.0 docker-pycreds-0.4.0 docutils-0.16 e3nn-0.5.0 emlp-1.0.2 exmol-2.1.1 gitdb-4.0.9 gsd-2.6.0 huggingface-hub-0.10.1 importlib-resources-5.6.0 jedi-0.18.1 jmp-0.0.2 jsonschema-3.2.0 jupyter-book-0.12.3 jupyter-cache-0.4.3 jupyter-server-1.21.0 jupyter-server-mathjax-0.2.6 jupyter-sphinx-0.3.2 jupyterlab-pygments-0.2.2 latexcodec-2.0.1 linkify-it-py-1.0.3 markdown-it-py-1.1.0 mdit-py-plugins-0.2.8 mmtf-python-1.1.3 mordred-1.2.0 mrcfile-1.4.3 multiprocess-0.70.13 myst-nb-0.13.2 myst-parser-0.15.2 nbclient-0.5.13 nbconvert-6.5.4 nbdime-3.1.1 nest-asyncio-1.5.6 objax-1.6.0 opt-einsum-fx-0.1.4 optax-0.1.3 packaging-20.9 parameterized-0.8.1 pathtools-0.1.2 pillow-9.2.0 plum-dispatch-1.7.4 prometheus-client-0.15.0 pybtex-0.24.0 pybtex-docutils-1.0.2 pydata-sphinx-theme-0.7.2 pydeck-0.8.0b4 pympler-1.0.1 ratelimit-2.2.1 rdkit-2022.9.1 rdkit-pypi-2022.9.1 responses-0.18.0 rich-12.6.0 selfies-2.1.1 semver-2.13.0 sentencepiece-0.1.97 sentry-sdk-1.9.0 seqeval-1.2.2 setproctitle-1.3.2 shortuuid-1.0.9 simpletransformers-0.63.9 sklearn-0.0 skunk-0.4.0 smmap-5.0.0 sniffio-1.3.0 sphinx-4.5.0 sphinx-book-theme-0.1.10 sphinx-comments-0.0.3 sphinx-copybutton-0.5.0 sphinx-external-toc-0.2.4 sphinx-jupyterbook-latex-0.4.7 sphinx-multitoc-numbering-0.1.3 sphinx-panels-0.6.0 sphinx-thebe-0.1.2 sphinx-togglebutton-0.3.2 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-bibtex-2.5.0 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 streamlit-1.13.0 tensorflowjs-3.18.0 tinycss2-1.2.1 tokenizers-0.13.1 tornado-6.2 transformers-4.23.1 uc-micro-py-1.0.1 urllib3-1.25.11 validators-0.20.0 wandb-0.13.4 watchdog-2.1.9 websocket-client-1.4.1 xxhash-3.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","sphinxcontrib","tornado"]}}},"metadata":{}}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"4YbkujizDtv3","executionInfo":{"status":"ok","timestamp":1666805530635,"user_tz":-60,"elapsed":2509,"user":{"displayName":"Ted Pitman","userId":"14049291477165845436"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import rdkit, rdkit.Chem, rdkit.Chem.Draw\n","import numpy as np\n","import jax.numpy as jnp\n","import mordred, mordred.descriptors\n","import jax\n","import dmol"]},{"cell_type":"markdown","metadata":{"id":"Ao1j3KExDtv4"},"source":["Now we load the data. This is a little fancy because we're extracting the data file from a zip archive on a website. "]},{"cell_type":"code","execution_count":2,"metadata":{"id":"xcgFOCizDtv5","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1666805536235,"user_tz":-60,"elapsed":898,"user":{"displayName":"Ted Pitman","userId":"14049291477165845436"}},"outputId":"cadef6b0-f797-4b0c-cbb4-d45fb42ad8e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                              smiles  FDA_APPROVED  CT_TOX\n","0            *C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC             1       0\n","1  [C@@H]1([C@@H]([C@@H]([C@H]([C@@H]([C@@H]1Cl)C...             1       0\n","2  [C@H]([C@@H]([C@@H](C(=O)[O-])O)O)([C@H](C(=O)...             1       0\n","3  [H]/[NH+]=C(/C1=CC(=O)/C(=C\\C=c2ccc(=C([NH3+])...             1       0\n","4  [H]/[NH+]=C(\\N)/c1ccc(cc1)OCCCCCOc2ccc(cc2)/C(...             1       0"],"text/html":["\n","  <div id=\"df-a7eebd55-cc57-41d3-a23b-6a26bc57edd7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>smiles</th>\n","      <th>FDA_APPROVED</th>\n","      <th>CT_TOX</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>*C(=O)[C@H](CCCCNC(=O)OCCOC)NC(=O)OCCOC</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[C@@H]1([C@@H]([C@@H]([C@H]([C@@H]([C@@H]1Cl)C...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[C@H]([C@@H]([C@@H](C(=O)[O-])O)O)([C@H](C(=O)...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[H]/[NH+]=C(/C1=CC(=O)/C(=C\\C=c2ccc(=C([NH3+])...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[H]/[NH+]=C(\\N)/c1ccc(cc1)OCCCCCOc2ccc(cc2)/C(...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7eebd55-cc57-41d3-a23b-6a26bc57edd7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a7eebd55-cc57-41d3-a23b-6a26bc57edd7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a7eebd55-cc57-41d3-a23b-6a26bc57edd7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}],"source":["# from zipfile import ZipFile\n","# from io import BytesIO\n","# from urllib.request import urlopen\n","\n","# from web version\n","# url = 'https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/clintox.csv.gz'\n","# file = urlopen(url).read()\n","# file = BytesIO(file)\n","# document = ZipFile(file)\n","# toxdata = pd.read_csv(document.open('clintox.csv'))\n","\n","# local version\n","toxdata = pd.read_csv(\n","    \"https://github.com/whitead/dmol-book/raw/master/data/clintox.csv.gz\"\n",")\n","toxdata.head()"]},{"cell_type":"markdown","metadata":{"id":"nBLU1hGuDtv5"},"source":["## Molecular Descriptors\n","\n","This time, our data does not come with pre-computed descriptors. We only have the SMILES string, which is a way of writing a molecule using letters and numbers (a string). We can use rdkit to convert the SMILES string into a molecule, and then we can use a package called Mordred {cite}`moriwaki2018mordred` to compute a set of descriptors for each molecule. This package will compute around 1500 descriptors for each molecule. \n","\n","We'll start by converting our molecules into rdkit objects and building a calculator to compute the descriptors."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"txmFSMPPDtv6","colab":{"base_uri":"https://localhost:8080/","height":172},"executionInfo":{"status":"ok","timestamp":1666805542724,"user_tz":-60,"elapsed":1018,"user":{"displayName":"Ted Pitman","userId":"14049291477165845436"}},"outputId":"31602c9b-c57e-44d1-b73e-bfae32949c28"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<rdkit.Chem.rdchem.Mol at 0x7efd8c634ad0>"],"text/html":["<?xml version='1.0' encoding='iso-8859-1'?>\n","<svg version='1.1' baseProfile='full'\n","              xmlns='http://www.w3.org/2000/svg'\n","                      xmlns:rdkit='http://www.rdkit.org/xml'\n","                      xmlns:xlink='http://www.w3.org/1999/xlink'\n","                  xml:space='preserve'\n","width='450px' height='150px' viewBox='0 0 450 150'>\n","<!-- END OF HEADER -->\n","<rect style='opacity:1.0;fill:#FFFFFF;stroke:none' width='450.0' height='150.0' x='0.0' y='0.0'> </rect>\n","<path class='bond-0 atom-0 atom-1' d='M 126.3,33.3 L 141.2,27.3' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-1 atom-1 atom-2' d='M 142.4,28.2 L 144.6,12.8' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-1 atom-1 atom-2' d='M 139.7,27.8 L 141.9,12.5' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-2 atom-1 atom-3' d='M 141.2,27.3 L 155.4,38.4' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-3 atom-3 atom-4' d='M 158.8,37.4 L 158.6,36.7' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-3 atom-3 atom-4' d='M 162.3,36.3 L 161.8,35.1' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-3 atom-3 atom-4' d='M 165.8,35.3 L 165.0,33.4' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-3 atom-3 atom-4' d='M 169.2,34.3 L 168.2,31.8' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-4 atom-4 atom-5' d='M 172.1,31.6 L 186.3,42.8' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-5 atom-5 atom-6' d='M 186.3,42.8 L 203.0,36.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-6 atom-6 atom-7' d='M 203.0,36.0 L 217.2,47.2' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-7 atom-7 atom-8' d='M 217.2,47.2 L 231.4,41.5' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-8 atom-8 atom-9' d='M 236.5,42.4 L 248.2,51.6' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-9 atom-9 atom-10' d='M 246.9,50.6 L 244.7,66.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-9 atom-9 atom-10' d='M 249.6,51.0 L 247.4,66.4' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-10 atom-9 atom-11' d='M 248.2,51.6 L 262.0,46.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-11 atom-11 atom-12' d='M 267.8,47.1 L 279.1,55.9' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-12 atom-12 atom-13' d='M 279.1,55.9 L 295.8,49.2' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-13 atom-13 atom-14' d='M 295.8,49.2 L 307.1,58.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-14 atom-14 atom-15' d='M 313.0,59.2 L 326.8,53.6' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-15 atom-3 atom-16' d='M 155.4,38.4 L 153.3,53.1' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-16 atom-16 atom-17' d='M 155.4,58.2 L 167.0,67.4' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-17 atom-17 atom-18' d='M 166.8,68.9 L 181.3,63.1' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-17 atom-17 atom-18' d='M 165.8,66.4 L 180.3,60.6' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-18 atom-17 atom-19' d='M 167.0,67.4 L 165.0,82.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-19 atom-19 atom-20' d='M 167.4,87.5 L 178.7,96.3' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-20 atom-20 atom-21' d='M 178.7,96.3 L 176.2,114.2' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-21 atom-21 atom-22' d='M 176.2,114.2 L 187.4,123.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path class='bond-22 atom-22 atom-23' d='M 189.9,128.6 L 187.8,143.2' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n","<path d='M 140.4,27.6 L 141.2,27.3 L 141.9,27.8' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path d='M 154.7,37.8 L 155.4,38.4 L 155.3,39.1' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path d='M 185.6,42.2 L 186.3,42.8 L 187.1,42.4' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path d='M 202.2,36.4 L 203.0,36.0 L 203.8,36.6' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path d='M 216.5,46.6 L 217.2,47.2 L 217.9,46.9' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path d='M 247.6,51.1 L 248.2,51.6 L 248.9,51.3' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path d='M 278.5,55.5 L 279.1,55.9 L 279.9,55.6' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path d='M 295.0,49.6 L 295.8,49.2 L 296.4,49.7' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path d='M 166.5,66.9 L 167.0,67.4 L 166.9,68.1' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path d='M 178.1,95.9 L 178.7,96.3 L 178.6,97.2' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path d='M 176.3,113.3 L 176.2,114.2 L 176.7,114.6' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n","<path class='atom-0' d='M 123.5 33.4\n","L 124.2 32.7\n","L 123.2 32.5\n","L 123.4 31.9\n","L 124.3 32.4\n","L 124.2 31.4\n","L 124.7 31.4\n","L 124.6 32.4\n","L 125.5 32.0\n","L 125.7 32.5\n","L 124.6 32.6\n","L 125.4 33.4\n","L 124.9 33.7\n","L 124.4 32.8\n","L 123.9 33.7\n","L 123.5 33.4\n","' fill='#000000'/>\n","<path class='atom-2' d='M 141.4 9.4\n","Q 141.4 8.2, 142.0 7.5\n","Q 142.6 6.8, 143.7 6.8\n","Q 144.9 6.8, 145.5 7.5\n","Q 146.1 8.2, 146.1 9.4\n","Q 146.1 10.7, 145.5 11.4\n","Q 144.8 12.1, 143.7 12.1\n","Q 142.6 12.1, 142.0 11.4\n","Q 141.4 10.7, 141.4 9.4\n","M 143.7 11.5\n","Q 144.5 11.5, 144.9 11.0\n","Q 145.3 10.4, 145.3 9.4\n","Q 145.3 8.4, 144.9 7.9\n","Q 144.5 7.4, 143.7 7.4\n","Q 142.9 7.4, 142.5 7.9\n","Q 142.1 8.4, 142.1 9.4\n","Q 142.1 10.4, 142.5 11.0\n","Q 142.9 11.5, 143.7 11.5\n","' fill='#000000'/>\n","<path class='atom-8' d='M 232.8 37.9\n","L 234.5 40.6\n","Q 234.7 40.9, 234.9 41.3\n","Q 235.2 41.8, 235.2 41.8\n","L 235.2 37.9\n","L 235.9 37.9\n","L 235.9 43.0\n","L 235.2 43.0\n","L 233.4 40.0\n","Q 233.2 39.7, 233.0 39.3\n","Q 232.8 38.9, 232.7 38.8\n","L 232.7 43.0\n","L 232.0 43.0\n","L 232.0 37.9\n","L 232.8 37.9\n","' fill='#000000'/>\n","<path class='atom-8' d='M 232.0 32.3\n","L 232.7 32.3\n","L 232.7 34.4\n","L 235.3 34.4\n","L 235.3 32.3\n","L 236.0 32.3\n","L 236.0 37.4\n","L 235.3 37.4\n","L 235.3 35.0\n","L 232.7 35.0\n","L 232.7 37.4\n","L 232.0 37.4\n","L 232.0 32.3\n","' fill='#000000'/>\n","<path class='atom-10' d='M 243.3 69.4\n","Q 243.3 68.2, 243.9 67.5\n","Q 244.5 66.8, 245.6 66.8\n","Q 246.8 66.8, 247.4 67.5\n","Q 248.0 68.2, 248.0 69.4\n","Q 248.0 70.7, 247.4 71.4\n","Q 246.8 72.1, 245.6 72.1\n","Q 244.5 72.1, 243.9 71.4\n","Q 243.3 70.7, 243.3 69.4\n","M 245.6 71.5\n","Q 246.4 71.5, 246.8 71.0\n","Q 247.3 70.5, 247.3 69.4\n","Q 247.3 68.4, 246.8 67.9\n","Q 246.4 67.4, 245.6 67.4\n","Q 244.9 67.4, 244.4 67.9\n","Q 244.0 68.4, 244.0 69.4\n","Q 244.0 70.5, 244.4 71.0\n","Q 244.9 71.5, 245.6 71.5\n","' fill='#000000'/>\n","<path class='atom-11' d='M 262.6 44.8\n","Q 262.6 43.6, 263.2 42.9\n","Q 263.8 42.2, 264.9 42.2\n","Q 266.0 42.2, 266.6 42.9\n","Q 267.2 43.6, 267.2 44.8\n","Q 267.2 46.1, 266.6 46.8\n","Q 266.0 47.5, 264.9 47.5\n","Q 263.8 47.5, 263.2 46.8\n","Q 262.6 46.1, 262.6 44.8\n","M 264.9 46.9\n","Q 265.7 46.9, 266.1 46.4\n","Q 266.5 45.9, 266.5 44.8\n","Q 266.5 43.8, 266.1 43.3\n","Q 265.7 42.8, 264.9 42.8\n","Q 264.1 42.8, 263.7 43.3\n","Q 263.3 43.8, 263.3 44.8\n","Q 263.3 45.9, 263.7 46.4\n","Q 264.1 46.9, 264.9 46.9\n","' fill='#000000'/>\n","<path class='atom-14' d='M 307.7 60.4\n","Q 307.7 59.1, 308.3 58.4\n","Q 308.9 57.8, 310.0 57.8\n","Q 311.2 57.8, 311.8 58.4\n","Q 312.4 59.1, 312.4 60.4\n","Q 312.4 61.6, 311.8 62.3\n","Q 311.1 63.0, 310.0 63.0\n","Q 308.9 63.0, 308.3 62.3\n","Q 307.7 61.6, 307.7 60.4\n","M 310.0 62.4\n","Q 310.8 62.4, 311.2 61.9\n","Q 311.6 61.4, 311.6 60.4\n","Q 311.6 59.4, 311.2 58.8\n","Q 310.8 58.3, 310.0 58.3\n","Q 309.2 58.3, 308.8 58.8\n","Q 308.4 59.3, 308.4 60.4\n","Q 308.4 61.4, 308.8 61.9\n","Q 309.2 62.4, 310.0 62.4\n","' fill='#000000'/>\n","<path class='atom-16' d='M 145.9 53.7\n","L 146.6 53.7\n","L 146.6 55.9\n","L 149.2 55.9\n","L 149.2 53.7\n","L 149.9 53.7\n","L 149.9 58.8\n","L 149.2 58.8\n","L 149.2 56.4\n","L 146.6 56.4\n","L 146.6 58.8\n","L 145.9 58.8\n","L 145.9 53.7\n","' fill='#000000'/>\n","<path class='atom-16' d='M 151.7 53.7\n","L 153.4 56.4\n","Q 153.6 56.7, 153.8 57.1\n","Q 154.1 57.6, 154.1 57.7\n","L 154.1 53.7\n","L 154.8 53.7\n","L 154.8 58.8\n","L 154.1 58.8\n","L 152.3 55.8\n","Q 152.1 55.5, 151.9 55.1\n","Q 151.6 54.7, 151.6 54.6\n","L 151.6 58.8\n","L 150.9 58.8\n","L 150.9 53.7\n","L 151.7 53.7\n","' fill='#000000'/>\n","<path class='atom-18' d='M 181.4 60.6\n","Q 181.4 59.4, 182.0 58.7\n","Q 182.6 58.0, 183.8 58.0\n","Q 184.9 58.0, 185.5 58.7\n","Q 186.1 59.4, 186.1 60.6\n","Q 186.1 61.9, 185.5 62.6\n","Q 184.9 63.3, 183.8 63.3\n","Q 182.6 63.3, 182.0 62.6\n","Q 181.4 61.9, 181.4 60.6\n","M 183.8 62.7\n","Q 184.6 62.7, 185.0 62.2\n","Q 185.4 61.7, 185.4 60.6\n","Q 185.4 59.6, 185.0 59.1\n","Q 184.6 58.6, 183.8 58.6\n","Q 183.0 58.6, 182.6 59.1\n","Q 182.2 59.6, 182.2 60.6\n","Q 182.2 61.7, 182.6 62.2\n","Q 183.0 62.7, 183.8 62.7\n","' fill='#000000'/>\n","<path class='atom-19' d='M 162.2 85.2\n","Q 162.2 84.0, 162.8 83.3\n","Q 163.4 82.6, 164.5 82.6\n","Q 165.6 82.6, 166.2 83.3\n","Q 166.9 84.0, 166.9 85.2\n","Q 166.9 86.5, 166.2 87.2\n","Q 165.6 87.9, 164.5 87.9\n","Q 163.4 87.9, 162.8 87.2\n","Q 162.2 86.5, 162.2 85.2\n","M 164.5 87.3\n","Q 165.3 87.3, 165.7 86.8\n","Q 166.1 86.3, 166.1 85.2\n","Q 166.1 84.2, 165.7 83.7\n","Q 165.3 83.2, 164.5 83.2\n","Q 163.7 83.2, 163.3 83.7\n","Q 162.9 84.2, 162.9 85.2\n","Q 162.9 86.3, 163.3 86.8\n","Q 163.7 87.3, 164.5 87.3\n","' fill='#000000'/>\n","<path class='atom-22' d='M 188.0 125.3\n","Q 188.0 124.1, 188.6 123.4\n","Q 189.2 122.7, 190.4 122.7\n","Q 191.5 122.7, 192.1 123.4\n","Q 192.7 124.1, 192.7 125.3\n","Q 192.7 126.6, 192.1 127.3\n","Q 191.5 128.0, 190.4 128.0\n","Q 189.2 128.0, 188.6 127.3\n","Q 188.0 126.6, 188.0 125.3\n","M 190.4 127.4\n","Q 191.1 127.4, 191.6 126.9\n","Q 192.0 126.4, 192.0 125.3\n","Q 192.0 124.3, 191.6 123.8\n","Q 191.1 123.3, 190.4 123.3\n","Q 189.6 123.3, 189.2 123.8\n","Q 188.7 124.3, 188.7 125.3\n","Q 188.7 126.4, 189.2 126.9\n","Q 189.6 127.4, 190.4 127.4\n","' fill='#000000'/>\n","</svg>\n"],"image/svg+xml":"<?xml version='1.0' encoding='iso-8859-1'?>\n<svg version='1.1' baseProfile='full'\n              xmlns='http://www.w3.org/2000/svg'\n                      xmlns:rdkit='http://www.rdkit.org/xml'\n                      xmlns:xlink='http://www.w3.org/1999/xlink'\n                  xml:space='preserve'\nwidth='450px' height='150px' viewBox='0 0 450 150'>\n<!-- END OF HEADER -->\n<rect style='opacity:1.0;fill:#FFFFFF;stroke:none' width='450.0' height='150.0' x='0.0' y='0.0'> </rect>\n<path class='bond-0 atom-0 atom-1' d='M 126.3,33.3 L 141.2,27.3' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-1 atom-1 atom-2' d='M 142.4,28.2 L 144.6,12.8' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-1 atom-1 atom-2' d='M 139.7,27.8 L 141.9,12.5' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-2 atom-1 atom-3' d='M 141.2,27.3 L 155.4,38.4' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-3 atom-3 atom-4' d='M 158.8,37.4 L 158.6,36.7' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-3 atom-3 atom-4' d='M 162.3,36.3 L 161.8,35.1' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-3 atom-3 atom-4' d='M 165.8,35.3 L 165.0,33.4' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-3 atom-3 atom-4' d='M 169.2,34.3 L 168.2,31.8' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:1.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-4 atom-4 atom-5' d='M 172.1,31.6 L 186.3,42.8' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-5 atom-5 atom-6' d='M 186.3,42.8 L 203.0,36.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-6 atom-6 atom-7' d='M 203.0,36.0 L 217.2,47.2' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-7 atom-7 atom-8' d='M 217.2,47.2 L 231.4,41.5' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-8 atom-8 atom-9' d='M 236.5,42.4 L 248.2,51.6' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-9 atom-9 atom-10' d='M 246.9,50.6 L 244.7,66.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-9 atom-9 atom-10' d='M 249.6,51.0 L 247.4,66.4' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-10 atom-9 atom-11' d='M 248.2,51.6 L 262.0,46.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-11 atom-11 atom-12' d='M 267.8,47.1 L 279.1,55.9' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-12 atom-12 atom-13' d='M 279.1,55.9 L 295.8,49.2' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-13 atom-13 atom-14' d='M 295.8,49.2 L 307.1,58.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-14 atom-14 atom-15' d='M 313.0,59.2 L 326.8,53.6' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-15 atom-3 atom-16' d='M 155.4,38.4 L 153.3,53.1' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-16 atom-16 atom-17' d='M 155.4,58.2 L 167.0,67.4' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-17 atom-17 atom-18' d='M 166.8,68.9 L 181.3,63.1' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-17 atom-17 atom-18' d='M 165.8,66.4 L 180.3,60.6' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-18 atom-17 atom-19' d='M 167.0,67.4 L 165.0,82.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-19 atom-19 atom-20' d='M 167.4,87.5 L 178.7,96.3' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-20 atom-20 atom-21' d='M 178.7,96.3 L 176.2,114.2' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-21 atom-21 atom-22' d='M 176.2,114.2 L 187.4,123.0' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path class='bond-22 atom-22 atom-23' d='M 189.9,128.6 L 187.8,143.2' style='fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1' />\n<path d='M 140.4,27.6 L 141.2,27.3 L 141.9,27.8' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path d='M 154.7,37.8 L 155.4,38.4 L 155.3,39.1' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path d='M 185.6,42.2 L 186.3,42.8 L 187.1,42.4' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path d='M 202.2,36.4 L 203.0,36.0 L 203.8,36.6' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path d='M 216.5,46.6 L 217.2,47.2 L 217.9,46.9' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path d='M 247.6,51.1 L 248.2,51.6 L 248.9,51.3' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path d='M 278.5,55.5 L 279.1,55.9 L 279.9,55.6' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path d='M 295.0,49.6 L 295.8,49.2 L 296.4,49.7' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path d='M 166.5,66.9 L 167.0,67.4 L 166.9,68.1' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path d='M 178.1,95.9 L 178.7,96.3 L 178.6,97.2' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path d='M 176.3,113.3 L 176.2,114.2 L 176.7,114.6' style='fill:none;stroke:#000000;stroke-width:2.0px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1;' />\n<path class='atom-0' d='M 123.5 33.4\nL 124.2 32.7\nL 123.2 32.5\nL 123.4 31.9\nL 124.3 32.4\nL 124.2 31.4\nL 124.7 31.4\nL 124.6 32.4\nL 125.5 32.0\nL 125.7 32.5\nL 124.6 32.6\nL 125.4 33.4\nL 124.9 33.7\nL 124.4 32.8\nL 123.9 33.7\nL 123.5 33.4\n' fill='#000000'/>\n<path class='atom-2' d='M 141.4 9.4\nQ 141.4 8.2, 142.0 7.5\nQ 142.6 6.8, 143.7 6.8\nQ 144.9 6.8, 145.5 7.5\nQ 146.1 8.2, 146.1 9.4\nQ 146.1 10.7, 145.5 11.4\nQ 144.8 12.1, 143.7 12.1\nQ 142.6 12.1, 142.0 11.4\nQ 141.4 10.7, 141.4 9.4\nM 143.7 11.5\nQ 144.5 11.5, 144.9 11.0\nQ 145.3 10.4, 145.3 9.4\nQ 145.3 8.4, 144.9 7.9\nQ 144.5 7.4, 143.7 7.4\nQ 142.9 7.4, 142.5 7.9\nQ 142.1 8.4, 142.1 9.4\nQ 142.1 10.4, 142.5 11.0\nQ 142.9 11.5, 143.7 11.5\n' fill='#000000'/>\n<path class='atom-8' d='M 232.8 37.9\nL 234.5 40.6\nQ 234.7 40.9, 234.9 41.3\nQ 235.2 41.8, 235.2 41.8\nL 235.2 37.9\nL 235.9 37.9\nL 235.9 43.0\nL 235.2 43.0\nL 233.4 40.0\nQ 233.2 39.7, 233.0 39.3\nQ 232.8 38.9, 232.7 38.8\nL 232.7 43.0\nL 232.0 43.0\nL 232.0 37.9\nL 232.8 37.9\n' fill='#000000'/>\n<path class='atom-8' d='M 232.0 32.3\nL 232.7 32.3\nL 232.7 34.4\nL 235.3 34.4\nL 235.3 32.3\nL 236.0 32.3\nL 236.0 37.4\nL 235.3 37.4\nL 235.3 35.0\nL 232.7 35.0\nL 232.7 37.4\nL 232.0 37.4\nL 232.0 32.3\n' fill='#000000'/>\n<path class='atom-10' d='M 243.3 69.4\nQ 243.3 68.2, 243.9 67.5\nQ 244.5 66.8, 245.6 66.8\nQ 246.8 66.8, 247.4 67.5\nQ 248.0 68.2, 248.0 69.4\nQ 248.0 70.7, 247.4 71.4\nQ 246.8 72.1, 245.6 72.1\nQ 244.5 72.1, 243.9 71.4\nQ 243.3 70.7, 243.3 69.4\nM 245.6 71.5\nQ 246.4 71.5, 246.8 71.0\nQ 247.3 70.5, 247.3 69.4\nQ 247.3 68.4, 246.8 67.9\nQ 246.4 67.4, 245.6 67.4\nQ 244.9 67.4, 244.4 67.9\nQ 244.0 68.4, 244.0 69.4\nQ 244.0 70.5, 244.4 71.0\nQ 244.9 71.5, 245.6 71.5\n' fill='#000000'/>\n<path class='atom-11' d='M 262.6 44.8\nQ 262.6 43.6, 263.2 42.9\nQ 263.8 42.2, 264.9 42.2\nQ 266.0 42.2, 266.6 42.9\nQ 267.2 43.6, 267.2 44.8\nQ 267.2 46.1, 266.6 46.8\nQ 266.0 47.5, 264.9 47.5\nQ 263.8 47.5, 263.2 46.8\nQ 262.6 46.1, 262.6 44.8\nM 264.9 46.9\nQ 265.7 46.9, 266.1 46.4\nQ 266.5 45.9, 266.5 44.8\nQ 266.5 43.8, 266.1 43.3\nQ 265.7 42.8, 264.9 42.8\nQ 264.1 42.8, 263.7 43.3\nQ 263.3 43.8, 263.3 44.8\nQ 263.3 45.9, 263.7 46.4\nQ 264.1 46.9, 264.9 46.9\n' fill='#000000'/>\n<path class='atom-14' d='M 307.7 60.4\nQ 307.7 59.1, 308.3 58.4\nQ 308.9 57.8, 310.0 57.8\nQ 311.2 57.8, 311.8 58.4\nQ 312.4 59.1, 312.4 60.4\nQ 312.4 61.6, 311.8 62.3\nQ 311.1 63.0, 310.0 63.0\nQ 308.9 63.0, 308.3 62.3\nQ 307.7 61.6, 307.7 60.4\nM 310.0 62.4\nQ 310.8 62.4, 311.2 61.9\nQ 311.6 61.4, 311.6 60.4\nQ 311.6 59.4, 311.2 58.8\nQ 310.8 58.3, 310.0 58.3\nQ 309.2 58.3, 308.8 58.8\nQ 308.4 59.3, 308.4 60.4\nQ 308.4 61.4, 308.8 61.9\nQ 309.2 62.4, 310.0 62.4\n' fill='#000000'/>\n<path class='atom-16' d='M 145.9 53.7\nL 146.6 53.7\nL 146.6 55.9\nL 149.2 55.9\nL 149.2 53.7\nL 149.9 53.7\nL 149.9 58.8\nL 149.2 58.8\nL 149.2 56.4\nL 146.6 56.4\nL 146.6 58.8\nL 145.9 58.8\nL 145.9 53.7\n' fill='#000000'/>\n<path class='atom-16' d='M 151.7 53.7\nL 153.4 56.4\nQ 153.6 56.7, 153.8 57.1\nQ 154.1 57.6, 154.1 57.7\nL 154.1 53.7\nL 154.8 53.7\nL 154.8 58.8\nL 154.1 58.8\nL 152.3 55.8\nQ 152.1 55.5, 151.9 55.1\nQ 151.6 54.7, 151.6 54.6\nL 151.6 58.8\nL 150.9 58.8\nL 150.9 53.7\nL 151.7 53.7\n' fill='#000000'/>\n<path class='atom-18' d='M 181.4 60.6\nQ 181.4 59.4, 182.0 58.7\nQ 182.6 58.0, 183.8 58.0\nQ 184.9 58.0, 185.5 58.7\nQ 186.1 59.4, 186.1 60.6\nQ 186.1 61.9, 185.5 62.6\nQ 184.9 63.3, 183.8 63.3\nQ 182.6 63.3, 182.0 62.6\nQ 181.4 61.9, 181.4 60.6\nM 183.8 62.7\nQ 184.6 62.7, 185.0 62.2\nQ 185.4 61.7, 185.4 60.6\nQ 185.4 59.6, 185.0 59.1\nQ 184.6 58.6, 183.8 58.6\nQ 183.0 58.6, 182.6 59.1\nQ 182.2 59.6, 182.2 60.6\nQ 182.2 61.7, 182.6 62.2\nQ 183.0 62.7, 183.8 62.7\n' fill='#000000'/>\n<path class='atom-19' d='M 162.2 85.2\nQ 162.2 84.0, 162.8 83.3\nQ 163.4 82.6, 164.5 82.6\nQ 165.6 82.6, 166.2 83.3\nQ 166.9 84.0, 166.9 85.2\nQ 166.9 86.5, 166.2 87.2\nQ 165.6 87.9, 164.5 87.9\nQ 163.4 87.9, 162.8 87.2\nQ 162.2 86.5, 162.2 85.2\nM 164.5 87.3\nQ 165.3 87.3, 165.7 86.8\nQ 166.1 86.3, 166.1 85.2\nQ 166.1 84.2, 165.7 83.7\nQ 165.3 83.2, 164.5 83.2\nQ 163.7 83.2, 163.3 83.7\nQ 162.9 84.2, 162.9 85.2\nQ 162.9 86.3, 163.3 86.8\nQ 163.7 87.3, 164.5 87.3\n' fill='#000000'/>\n<path class='atom-22' d='M 188.0 125.3\nQ 188.0 124.1, 188.6 123.4\nQ 189.2 122.7, 190.4 122.7\nQ 191.5 122.7, 192.1 123.4\nQ 192.7 124.1, 192.7 125.3\nQ 192.7 126.6, 192.1 127.3\nQ 191.5 128.0, 190.4 128.0\nQ 189.2 128.0, 188.6 127.3\nQ 188.0 126.6, 188.0 125.3\nM 190.4 127.4\nQ 191.1 127.4, 191.6 126.9\nQ 192.0 126.4, 192.0 125.3\nQ 192.0 124.3, 191.6 123.8\nQ 191.1 123.3, 190.4 123.3\nQ 189.6 123.3, 189.2 123.8\nQ 188.7 124.3, 188.7 125.3\nQ 188.7 126.4, 189.2 126.9\nQ 189.6 127.4, 190.4 127.4\n' fill='#000000'/>\n</svg>\n","image/png":"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\n"},"metadata":{},"execution_count":3}],"source":["# make object that can compute descriptors\n","calc = mordred.Calculator(mordred.descriptors, ignore_3D=True)\n","# make subsample from pandas df\n","molecules = [rdkit.Chem.MolFromSmiles(smi) for smi in toxdata.smiles]\n","\n","# view one molecule to make sure things look good.\n","molecules[0]"]},{"cell_type":"markdown","metadata":{"id":"i1LWxpcYDtv6"},"source":["Some of our molecules failed to be converted. We'll have to remove them. We need to remember which ones were deleted too, since we need to remove the failed molecules from the labels."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"0dOVHw5jDtv6","executionInfo":{"status":"ok","timestamp":1666805562889,"user_tz":-60,"elapsed":204,"user":{"displayName":"Ted Pitman","userId":"14049291477165845436"}}},"outputs":[],"source":["# the invalid molecules were None, so we'll just\n","# use the fact the None is False in Python\n","valid_mol_idx = [bool(m) for m in molecules]\n","valid_mols = [m for m in molecules if m]"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"MhpCozWeDtv6","tags":["remove-output"],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666806470480,"user_tz":-60,"elapsed":798596,"user":{"displayName":"Ted Pitman","userId":"14049291477165845436"}},"outputId":"4d0489c7-b1fc-4386-fe81-66622ff47c86"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1478/1478 [15:05<00:00,  1.63it/s]\n"]}],"source":["features = calc.pandas(valid_mols)"]},{"cell_type":"markdown","metadata":{"id":"n1077JZQDtv7"},"source":["Now we just need to stich everything back together so that our labels are consistent and standardize our features. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJQtBlxJDtv7"},"outputs":[],"source":["labels = toxdata[valid_mol_idx].FDA_APPROVED\n","features -= features.mean()\n","features /= features.std()\n","\n","# we have some nans in features, likely because std was 0\n","features.dropna(inplace=True, axis=1)\n","\n","print(f\"We have {len(features.columns)} features per molecule\")"]},{"cell_type":"markdown","metadata":{"id":"5QpVHo5TDtv7"},"source":["## Classification Models\n","\n","### Linear Perceptron\n","\n","We are able to predict single values from regression. How can we go from a predicted value to a class? The simplest answer is to use the same linear regression equation from chapter {doc}`../ml/regression` $\\hat{f}(\\vec{x})$ and assign $\\hat{y} = 1$ when $\\hat{f}(\\vec{x}) > 0$,  $\\hat{y} = 0$ otherwise. Our model equation is then:\n","\n","\\begin{equation}\n","\\hat{f}(\\vec{x}) = \\begin{cases} \n","      1 & \\vec{w}\\cdot \\vec{x} + b > 0 \\\\\n","      0 & \\textrm{otherwise}\\\\\n","   \\end{cases}\n","\\end{equation}\n","\n","The term $\\vec{w}\\cdot \\vec{x} + b$ is called **distance from the decision boundary** where the decision boundary is at $\\vec{w}\\cdot \\vec{x} + b = 0$. If it is large, we are far away from classifying it as $0$. If it is small, we are close to classifying it as $0$. It can be loosely thought of as \"confidence\". "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M14yp0E_Dtv8"},"outputs":[],"source":["def perceptron(x, w, b):\n","    v = jnp.dot(x, w) + b\n","    y = jnp.where(v > 0, x=jnp.ones_like(v), y=jnp.zeros_like(v))\n","    return y"]},{"cell_type":"markdown","metadata":{"id":"AsFRyvBlDtv8"},"source":["This particular model is called a **perceptron** and is the first neural network for classification. It was invented in 1958 by Frank Rosenblatt, a psychologist at Cornell University. It was not the first neural network, but is often the first one that students learn. The perceptron is an example of a **hard** classifier; it does not predict probability of the class and instead predicts exactly one class. \n","\n","\n","Now that we have a model, we must choose a loss function. We haven't learned about many loss functions yet. We've only seen mean squared error. Let us begin with a related loss called mean absolute error (MAE). MAE measures disagreement between our class and the predicted class. This is like an accuracy -- what percentage of the time we're correct.\n","\n","\\begin{equation}\n","    L = \\frac{1}{N} \\sum_i  \\left|y_i - \\hat{y}_i\\right|\n","\\end{equation}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_9SI1FsDtv8"},"outputs":[],"source":["def loss(y, yhat):\n","    return jnp.mean(jnp.abs(y - yhat))\n","\n","\n","def loss_wrapper(w, b, x, y):\n","    yhat = perceptron(x, w, b)\n","    return loss(y, yhat)\n","\n","\n","loss_grad = jax.grad(loss_wrapper, (0, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJnPp-WiDtv9"},"outputs":[],"source":["batch_size = 32\n","train_N = int(len(labels) * 0.8)\n","\n","\n","N = len(labels)\n","batch_idx = range(0, train_N, batch_size)\n","w = np.random.normal(size=len(features.columns))\n","b = 0.0\n","\n","loss_grad = jax.grad(loss_wrapper, (0, 1))\n","\n","\n","test_x = features[train_N:].values.astype(np.float32)\n","test_y = labels[train_N:].values"]},{"cell_type":"markdown","metadata":{"id":"4AHfyXs4Dtv9"},"source":["Let's now try out our gradient to make sure it works"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lOx_q5I6Dtv9"},"outputs":[],"source":["loss_grad(w, b, test_x, test_y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r3WqkjLEDtv-","tags":["remove-cell"]},"outputs":[],"source":["from myst_nb import glue\n","\n","x = np.linspace(-3, 3, 500)\n","y = 1 / (1 + np.exp(-x))\n","plt.plot(x, y)\n","plt.xlabel(r\"$x$\")\n","plt.ylabel(r\"$\\sigma(x)$\")\n","plt.axvline(0, color=\"gray\")\n","plt.title(\"Sigmoid\")\n","glue(\"sigmoid\", plt.gcf(), display=False)"]},{"cell_type":"markdown","metadata":{"id":"SGCxleaVDtv-"},"source":["It's all zeros! Why is that? It's because our {obj}`jnp.where<jax.numpy.where>` statement above is not differentiable, nor are any inequalities where the result is a constant (`1` or `0` in our case). The perceptron actually has a special training procedure that is not related to its derivatives. One of the motivating reasons that deep learning is popular is that we do not need to construct a special training process for each model we construct -- like the training procedure for the perceptron. \n","\n","Rather than teach and discuss the special perceptron training procedure, we'll move to a more modern related classifier called a softmax binary classifier. This is a tiny change, the softmax binary classifier is:\n","\n","\\begin{equation}\n","\\hat{f}(\\vec{x}) = \\sigma\\left(\\vec{w}\\cdot \\vec{x} + b\\right)\n","\\end{equation}\n","\n","```{glue:figure} sigmoid\n","----\n","name: simgoid\n","----\n","The sigmoid function. Input is any real number and the output is a probability. Positive numbers map to probabilities greater than 0.5 and negative numbers to probabilities less than 0.5. \n","```\n","\n","```{margin}\n","Softmax is the generalization of sigmoid to multiple classes. Although we call our binary classifier a softmax classifier, it doesn't use the softmax function.\n","```\n","\n","where $\\sigma$ is the **sigmoid** function. The sigmoid has a domain of $(-\\infty, \\infty)$ and outputs a probability $(0, 1)$. The input to the sigmoid can be viewed as log-odds, called **logits** for short. Odds are ratios of probability -- odds of 1 means the probability of the class 1 is 0.5 and class 0 is 0.5. Odds of 2 means the probability of class 1 is 0.67 and class 0 is 0.33. Log-odds is the natural logarithm of that, so that log-odds of 0 means the odds are 1 and the output probability should be 0.5. One definition of the sigmoid is \n","\n","\\begin{equation}\n","\\sigma(x) = \\frac{1}{1 + e^{-x}}\n","\\end{equation}\n","\n","however in practice there are some complexities to implementing sigmoids to make sure they're numerically stable. This type of binary classifier is sometimes called **logistic regression** because we're regressing logits. \n","\n","In essence, all we've done is replacing the inequality of the perceptron with a smooth differentiable version. Just like previously, a positive number indicated class 1 (FDA approved) but now it's a continuum of numbers from 0.5 to 1.0. This is **soft** classification -- we give probabilities of class membership instead of hard assignment. However, our loss function now needs to be modified as well. "]},{"cell_type":"markdown","metadata":{"id":"bNhnPLHODtv-"},"source":["There is a different loss function that works better with classification called **cross-entropy**. You can experiment with mean absolute error or mean squared error with classification, but you'll find they are almost always worse than cross-entropy.\n","\n","Cross-entropy is a loss function that describes distance between two probability distributions. When minimized, the two probability distributions are identical. Cross-entropy is a simplification of the [Kullback–Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) which is a way to measure distance between two probability distributions. Technically it is not a distance since it's not symmetric with respect to its arguments. But in practice it is close enough to a distance that we treat it as one. \n","\n","How is comparing predicted values $\\hat{y}$ and $y$ like comparing two probability distributions? Even though these are both 1s and 0s in the case of hard classification, they do sum to 1, and so we consider them probability distributions. Cross-entropy is defined as:\n","\n","\\begin{equation}\n","    L = -\\sum_c^K y_c \\log \\hat{y_c}\n","\\end{equation}\n","\n","where $c$ indicates which class of the $K$ we're considering, and it's assumed that $\\sum_c^K y_c = 1$ and $\\sum_c^K \\hat{y}_c = 1$ like probabilities (and they are positive). In the case of binary classification (only two classes), this becomes:\n","\n","\\begin{equation}\n","    L = -\\left[ y_0 \\log \\hat{y_0} + y_1 \\log \\hat{y_1} \\right]\n","\\end{equation}\n","\n","where $y_0$ is for the first class and $y_1$ is for the second class. However, we also know that because these are probabilities that $y_1 = 1 - y_0$. We can rewrite to:\n","\n","\\begin{equation}\n","    L = -\\left[ y_0 \\log \\hat{y_0} + (1 - y_0) \\log ( 1- \\hat{y_0}) \\right]\n","\\end{equation}\n","\n","Finally, we can drop the indication of the class:\n","\n","\\begin{equation}\n","    L = -\\left[ y \\log \\hat{y} + (1 - y) \\log ( 1- \\hat{y}) \\right]\n","\\end{equation}\n","\n","\n","```{margin}\n","The correct way to avoid numerical instability in cross-entropy sigmoid classification is to have your model output the logits and you use a loss function that works on logits instead of probability. For example, {obj}`tf.nn.sigmoid_cross_entropy_with_logits`.\n","```\n","and this matches our data, where we have a single value for each label indicating if it is a class member. Now we have features, labels, loss, and a model. Let's create a batched gradient descent algorithm to train our classifier. Note, one change we need to do is use the built-in jax {obj}`jax.nn.sigmoid` function to avoid numerical instabilities and also add a small number to all logs to avoid numerical instabilities."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0OwHQBcDtv_"},"outputs":[],"source":["def bin_classifier(x, w, b):\n","    v = jnp.dot(x, w) + b\n","    y = jax.nn.sigmoid(v)\n","    return y\n","\n","\n","def cross_ent(y, yhat):\n","    return jnp.mean(-(y * jnp.log(yhat + 1e-10) + (1 - y) * jnp.log(1 - yhat + 1e-10)))\n","\n","\n","def loss_wrapper(w, b, x, y):\n","    yhat = bin_classifier(x, w, b)\n","    return cross_ent(y, yhat)\n","\n","\n","loss_grad = jax.grad(loss_wrapper, (0, 1))\n","w = np.random.normal(scale=0.01, size=len(features.columns))\n","b = 1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rWY6ESj6Dtv_"},"outputs":[],"source":["loss_progress = []\n","test_loss_progress = []\n","eta = 0.2\n","for epoch in range(5):\n","    for i in range(len(batch_idx) - 1):\n","        x = features[batch_idx[i] : batch_idx[i + 1]].values.astype(np.float32)\n","        y = labels[batch_idx[i] : batch_idx[i + 1]].values\n","        grad = loss_grad(w, b, x, y)\n","        w -= eta * grad[0]\n","        b -= eta * grad[1]\n","        loss_progress.append(loss_wrapper(w, b, x, y))\n","        test_loss_progress.append(loss_wrapper(w, b, test_x, test_y))\n","plt.plot(loss_progress, label=\"Training Loss\")\n","plt.plot(test_loss_progress, label=\"Testing Loss\")\n","\n","plt.xlabel(\"Step\")\n","plt.legend()\n","plt.ylabel(\"Loss\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"8gCAUAypDtwA"},"source":["We are making good progress with our classifier, as judged from testing loss. You can run the code longer, but I'll leave it at that. We have a reasonably well-trained model."]},{"cell_type":"markdown","metadata":{"id":"3aDuhvTiDtwA"},"source":["## Classification Metrics\n","\n","In regression, we assessed model performance with a parity plot, correlation coefficient, or mean squared error. In classification, we use slightly different metrics. The first metric is **accuracy**. Accuracy is the percentage of time that the predicted label matches the true label. We do not have a hard classifier, so we have to choose how to turn probability into a specific class. For now, we will choose the class with the highest probability. Let's see how this looks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWbuc2qUDtwA"},"outputs":[],"source":["def accuracy(y, yhat):\n","    # convert from prob to hard class\n","    hard_yhat = np.where(yhat > 0.5, np.ones_like(yhat), np.zeros_like(yhat))\n","    disagree = np.sum(np.abs(y - yhat))\n","    return 1 - disagree / len(y)\n","\n","\n","accuracy(test_y, bin_classifier(test_x, w, b))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EL8jRt0MDtwA","tags":["remove-cell"]},"outputs":[],"source":["glue(\"acc\", accuracy(test_y, bin_classifier(test_x, w, b)))"]},{"cell_type":"markdown","metadata":{"id":"4vuzrIOGDtwA"},"source":["An accuracy of {glue:text}`acc:.2f` seems quite reasonable! However, consider this model:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7gf4oMVQDtwB"},"outputs":[],"source":["def alt_classifier(x):\n","    return np.ones((x.shape[0]))\n","\n","\n","accuracy(test_y, alt_classifier(test_x))"]},{"cell_type":"markdown","metadata":{"id":"NvXgsT4PDtwB"},"source":["This model, which always returns 1, has better accuracy than our model. How is this possible? \n","\n","```{admonition} Answer\n",":class: tip, dropdown\n","If you examine the data, you'll see the majority of the molecules passed FDA clinical trials ($y = 1$), so that just guessing $1$ is a good strategy.\n","```"]},{"cell_type":"markdown","metadata":{"id":"x78lCHDQDtwC"},"source":["### Error Types\n","\n","Let's recall what we're trying to do. We're trying to predict if a molecule will make it through FDA clinical trials. Our model can be incorrect in two ways: it predicts a molecule will pass through clinical trials, but it actually fails. This is called a false positive. The other error is if we predict our drug will not make it through clinical trials, but it actually does. This is false negative.\n","\n","```{margin}\n","False positive are sometimes known as Type I (pronounced type one) and false negatives as Type II false negatives\n","```\n","\n","Our `alt_classifier` model, which simply reports everything as positive, has no false negative errors. It has many false positive errors. These two types of errors can be quantified. We're going to add one complexity -- **threshold**. Our model provides probabilities which we're converting into hard class memberships -- 1s and 0s. We have been choosing to just take the most probable class. However, we will now instead choose a threshold for when we report a positive (class 1). The rationale is that although we train our model to minimize cross-entropy, we may want to be more conservative or aggressive in our classification with the trained model. If we want to minimize false negatives, we can lower the threshold and report even predictions that have a probability of 30% as positive. Or, if we want to minimize false positives we may set our threshold so that our model must predict above 90% before we predict a positive."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_wlBwdcEDtwC"},"outputs":[],"source":["def error_types(y, yhat, threshold):\n","    hard_yhat = np.where(yhat >= threshold, np.ones_like(yhat), np.zeros_like(yhat))\n","    # predicted 1, actually was 0 -> 1 (bool to remove predicted 0, actually was 1)\n","    fp = np.sum((hard_yhat - y) > 0)\n","    # predicted 0, actually was 1 -> 1 (bool to remove predicted 1, actually was 0)\n","    fn = np.sum((y - hard_yhat) > 0)\n","    return fp, fn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nkQJ_PdTDtwD"},"outputs":[],"source":["print(\"Alt Classifier\", error_types(test_y, alt_classifier(test_x), 0.5))\n","print(\"Trained Classifier\", error_types(test_y, bin_classifier(test_x, w, b), 0.5))"]},{"cell_type":"markdown","metadata":{"id":"Qq6IL9qnDtwD"},"source":["Now we have a better sense of how our model does in comparison. The number of errors is indeed larger for our trained model, but it has a bit of balance between the two errors. What is more important? In our case, I would argue doing clinical trials that fail is worse than mistakenly not starting them. That is, false positives are worse than false negatives. Let's see if we can tune our threshold value to minimize false positives. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3j11ETYeDtwD"},"outputs":[],"source":["print(\"Threshold 0.7\", error_types(test_y, bin_classifier(test_x, w, b), 0.7))\n","print(\"Threshold 0.9\", error_types(test_y, bin_classifier(test_x, w, b), 0.9))\n","print(\"Threshold 0.95\", error_types(test_y, bin_classifier(test_x, w, b), 0.95))\n","print(\"Threshold 0.99\", error_types(test_y, bin_classifier(test_x, w, b), 0.99))"]},{"cell_type":"markdown","metadata":{"id":"bgcO3BdkDtwE"},"source":["By adjusting the threshold, we can achieve a balance of error more like what we desire for our model. We're able to have 1 false positives in fact, at the cost of missing 218 of the molecules. Now are we still predicting positives? Are we actually going to get some **true positives?** We can measure that as well"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBj3MVZLDtwE"},"outputs":[],"source":["total_pos = np.sum(test_y)\n","print(\n","    \"Total positives:\",\n","    total_pos,\n","    \"Predicted Positives:\",\n","    np.sum(bin_classifier(test_x, w, b) > 0.99),\n",")"]},{"cell_type":"markdown","metadata":{"id":"MPMLguTlDtwE"},"source":["Yes, our model is actually capable of predicting if molecules will pass FDA clinical trials with as few false positives as possible (1). A model that is capable of this tuning is an example of a good model. Our other model, that predicts 1s, has good accuracy but we cannot adjust it or try to better balance type I and type II errors. "]},{"cell_type":"markdown","metadata":{"id":"A5dV0HlzDtwE"},"source":["### Receiver-Operating Characteristic Curve\n","\n","We can plot threshold, false positive rate, and true positive rate all together on one plot to capture model accuracy and balance between error type in a Receiver-Operating Characteristic Curve (ROC curve). The x-axis of ROC curve is false positive rate and the y-axis is true positive rate. Each point on the plot is our model with different thresholds. How do we choose which thresholds to use? It is the set of unique class probabilities we saw (namely, {obj}`np.unique<numpy.unique>`). We do need to add two extremes to this set though: all positive (threshold of 0.0) and all negative (1.0). Recall our alternate/baseline model of always predicting positive: it can only have a few points on the the ROC curve because it's unique set of probabilities is just 1.0. Let's make one and discuss what we're seeing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xvrIo3e1DtwF"},"outputs":[],"source":["unique_threshes = np.unique(bin_classifier(test_x, w, b))\n","fp = []\n","tp = []\n","total_pos = np.sum(test_y)\n","for ut in list(unique_threshes) + [-0.1, 1.01]:\n","    errors = error_types(test_y, bin_classifier(test_x, w, b), ut)\n","    fp.append(errors[0])\n","    tp.append(total_pos - errors[1])\n","\n","# sort them so can plot as a line\n","idx = np.argsort(fp)\n","fpr = np.array(fp)[idx] / (len(test_y) - np.sum(test_y))\n","tpr = np.array(tp)[idx] / np.sum(test_y)\n","\n","# now remove duplicate x-values\n","fpr_nd = []\n","tpr_nd = []\n","last = None\n","for f, t in zip(fpr, tpr):\n","    if last is None or f != last:\n","        last = f\n","        fpr_nd.append(f)\n","        tpr_nd.append(t)\n","\n","plt.plot(fpr_nd, tpr_nd, \"-o\", label=\"Trained Model\")\n","plt.plot([0, 1], [0, 1], label=\"Naive Classifier\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"3hk4JjZRDtwF"},"source":["This plot nicely shows how our trained model is actually sensitive to threshold, so that we could choose to more carefully screen for false negative or false positives. The best curves fall to the top-left of this plot. Our naive classifier is where we return a fixed percentage of examples randomly as positive or negative. You can plot the area under this curve with an integration and this is a good way to measure classifier performance and correctly capture the effect of both false negatives and false positives. The area under the ROC curve is known as the **ROC AUC score** and is preferred to accuracy because it captures the balance of Type I and II errors."]},{"cell_type":"markdown","metadata":{"id":"GunRy3jlDtwG"},"source":["### Other metrics\n","\n","I will just mention that there are other ways to assess how your model balances the two error types. One major type is called **precision** and **recall**. Precision measures correctness of predicted positives and recall measures number of predicted positives. This can be a good viewpoint when doing molecular screening -- you may want to be very precise in that your proposed molecules are accurate while sacrificing recall. Recall here meaning you do not return very many molecules. Models on the left of an ROC curve are precise. Models at the top have good recall.  There are also F1 scores, likelihoods, Matthew's correlation coefficients, Jaccard index, Brier score, and balanced accuracy which all try to report one number which balances precision and recall. We will rarely explore these other measures but you should know they exist.\n","\n","#### Confusion Matrix\n","\n","A confusion matrix is a table of counts indicating true and predicted classes. They are one of many methods for binary classification, but really stand-out as good visual assessment for multiclass classification. For example, consider we are categorizing molecules into three classes: insoluble, weakly soluble, and soluble. We can represent a classifier's performance in a table:\n","\n","| truel👇\\predicted👉 | insoluble | weakly soluble | soluble |\n","|:--------------|:-----------:|:--------------:| -------:|\n","|   insoluble   |    121    |       8        |     1   |\n","| weakly soluble|    7      |       45        |     18   |\n","|    soluble    |    11    |       4        |     56   |\n","\n","\n","The diagonal elements show when the predicted and true labels agree. For example, 121 molecules were actually insoluble and predicted to be insolbule. We can also read how the classifier failed. One molecule was predicted to be soluble, but was actually insoluble. 4 molecules were predicted to be weakly soluble, but were actually soluble. This can help us understand *how* the classifier is failing."]},{"cell_type":"markdown","metadata":{"id":"jKfEkNBMDtwG"},"source":["## Class Imbalance\n","\n","The reason for this uneven amount of false positives and false negatives is that we have very few negative example -- molecules which failed FDA clinical trials. This also explains why just predicting success has a high accuracy. How can we address this problem?\n","\n","The first answer is do nothing. Is this imbalance a problem at all? Perhaps a drug in general will succeed at clinical trials and thus the imbalance in training data reflects what we expect to see in testing. This is clearly not the case, judging from the difficult and large expense of creating new drug molecules. However, this should be the first thing you ask yourself. If you're creating a classifier to detect lung cancer from X-ray images, probably you will have imbalanced training data and at test time, when evaluating patients, you'll also not have 50% of patients having lung cancer. This comes back to the discussion in the {doc}`regression` about training data distribution. If your testing data is within your training data distribution, then the class imbalance does not need to be explicitly addressed.\n","\n","The second solution is to somehow weight your training data to appear more like your testing data when you think you do have **label shift**. There are two ways to accomplish this. You could \"augment\" your training data by repeating the minority class until the ratio of minority to majority examples matches the assumed testing data. There are research papers written on this topic, with intuitive results{cite}`chawla2002smote`. You can over-sample minority class but that can lead to a large dataset, so you can also under-sample the majority class. This is a robust approach that is independent to how you train. It also is typically as good as more sophisticated methods {cite}`youbi2021simple`.\n","\n","Another method of weighing data is to modify your loss function to increase the gradient updates applied to minority examples. This is equivalent to saying there is a difference in loss between a false positive vs a false negative. In our case, false positive are rarer and also more important in reality. We would rather skip a clinical trial (false negative) rather than start one and have it fail (false positive). We already tried minimizing false positives by changing the threshold on a trained model but let's see how this works during training. We'll create a weight vector that is high for negative labels so that if they are misclassified (false positive), there will be a bigger update.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FbF1hZIpDtwG"},"outputs":[],"source":["def bin_classifier(x, w, b):\n","    v = jnp.dot(x, w) + b\n","    y = jax.nn.sigmoid(v)\n","    return y\n","\n","\n","def weighted_cross_ent(y, yhat, yw):\n","    # weights may not be normalized\n","    N = jnp.sum(yw)\n","    # use weighted sum instead\n","    return (\n","        jnp.sum(\n","            -(yw * y * jnp.log(yhat + 1e-10) + yw * (1 - y) * jnp.log(1 - yhat + 1e-10))\n","        )\n","        / N\n","    )\n","\n","\n","def loss_wrapper(w, b, x, y, yw):\n","    yhat = bin_classifier(x, w, b)\n","    return weighted_cross_ent(y, yhat, yw)\n","\n","\n","loss_grad = jax.grad(loss_wrapper, (0, 1))\n","w2 = np.random.normal(scale=0.01, size=len(features.columns))\n","b2 = 1.0\n","weights = np.ones_like(labels)\n","# make the labels = 0 values be much larger\n","weights[labels.values == 0] *= 1000\n","# now make weights be on average 1\n","# to keep our learning rate/avg update consistent\n","weights = weights * len(weights) / np.sum(weights)\n","\n","loss_progress = []\n","test_loss_progress = []\n","eta = 0.2\n","# make epochs larger since this has\n","# very large steps that converge poorly\n","for epoch in range(10):\n","    for i in range(len(batch_idx) - 1):\n","        x = features[batch_idx[i] : batch_idx[i + 1]].values.astype(np.float32)\n","        y = labels[batch_idx[i] : batch_idx[i + 1]].values\n","        yw = weights[batch_idx[i] : batch_idx[i + 1]]\n","        grad = loss_grad(w2, b2, x, y, yw)\n","        w2 -= eta * grad[0]\n","        b2 -= eta * grad[1]\n","        loss_progress.append(loss_wrapper(w2, b2, x, y, yw))\n","        test_loss_progress.append(\n","            loss_wrapper(w2, b2, test_x, test_y, np.ones_like(test_y))\n","        )\n","plt.plot(loss_progress, label=\"Training Loss\")\n","plt.plot(test_loss_progress, label=\"Testing Loss\")\n","\n","plt.xlabel(\"Step\")\n","plt.legend()\n","plt.ylabel(\"Loss\")\n","plt.show()\n","\n","print(\"Normal Classifier\", error_types(test_y, bin_classifier(test_x, w, b), 0.5))\n","print(\"Weighted Classifier\", error_types(test_y, bin_classifier(test_x, w2, b2), 0.5))"]},{"cell_type":"markdown","metadata":{"id":"hAaO0dfIDtwH"},"source":["The spikes in loss occur when we see a rare negative example, which are weighted heavily. Compared to the normal classifier trained above, we have fewer false positives at a threshold of 0.5. However, we also have more false negatives. We saw above that we could tweak this by changing our threshold. Let's see how our model looks on an ROC curve to compare our model trained with weighting with the previous model at all thresholds.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42tvh69XDtwH"},"outputs":[],"source":["unique_threshes = np.unique(bin_classifier(test_x, w2, b2))\n","fp = []\n","tp = []\n","total_pos = np.sum(test_y)\n","for ut in list(unique_threshes) + [-0.1, 1.01]:\n","    errors = error_types(test_y, bin_classifier(test_x, w2, b2), ut)\n","    fp.append(errors[0])\n","    tp.append(total_pos - errors[1])\n","\n","# sort them so can plot as a line\n","idx = np.argsort(fp)\n","fpr = np.array(fp)[idx] / (len(test_y) - np.sum(test_y))\n","tpr = np.array(tp)[idx] / np.sum(test_y)\n","\n","# now remove duplicate x-values\n","fpr_nd2 = []\n","tpr_nd2 = []\n","last = None\n","for f, t in zip(fpr, tpr):\n","    if last is None or f != last:\n","        last = f\n","        fpr_nd2.append(f)\n","        tpr_nd2.append(t)\n","\n","plt.plot(fpr_nd, tpr_nd, \"-o\", label=\"Normal Model\")\n","plt.plot(fpr_nd2, tpr_nd2, \"-o\", label=\"Weighted Model\")\n","plt.plot([0, 1], [0, 1], label=\"Naive Classifier\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.xlabel(\"False Positive Rate\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"-1KEJUl5DtwH"},"source":["It appears our weighted training actually did not improve model performance, except in a small range between 0.25-0.4 false positive rate. It is even worse in the low false positive rate, which is where we would like to operate. In conclusion, we can modify the balance of false positive and false negative through modifications to training. However, we can also modify this after training by affecting the threshold for classification. This post-training procedure gives similar or even slightly better performance in our example. \n","\n","This may not always be the case. An overview of methods are available in {cite}`he2009learning` and you can find a more recent discussion of the effects of reweighting, including when combined with regularization, in Bryrd and Lipton {cite}`byrd2019effect`. Byrd and Lipton show that reweighting has little effect unless combined with L2 regularization and batch normalization, perhaps accounting for the small effect we observed.\n","\n","### Screening: no negative examples\n","Class imbalance is common in peptide and drug discovery where screening is used to generate data. Screening typically only contains positive examples, meaning you have literally zero negative examples. This is an active topic of research in a field of **positive-unlabeled learning** {cite}`song2021inferring`\n","\n","\n","## Overfitting\n","\n","The goal of this chapter is to introduce classification. For simplicity, we did not use any of the techniques from the last chapter, except training/testing splitting. You can and should use techniques like Jacknife+ and cross-validation to assess overfitting. Also, our descriptor number was very high, a few hundred, and regularization could be helpful for these models. "]},{"cell_type":"markdown","metadata":{"id":"sU7Fp2-rDtwH"},"source":["## Chapter Summary\n","\n","* We introduced classification, which is supervised learning with categorical labels. The labels can be single binary values - representing 2 classes which is binary classification.\n","* We can compute descriptors for molecules using Python packages and do not require them to be part of our dataset\n","* Cross-entropy loss should be used for classification tasks\n","* Classification models (called classifiers) can output distance from decision boundary or, more commonly, probability of class\n","* The Perceptron is an early example of a neural network classifier that has a special training procedure\n","* The sigmoid and soft-max functions convert real numbers into probabilities\n","* Binary classification error can be false positives or false negatives\n","* Accuracy does not distinguish these two errors, so receive-operator characteristic (ROC) curves can be used to assess model performance. Precision and recall are other commonly used measures. \n","* An imbalance of classes in training data is not necessarily a problem and can be addressed by weighting training examples"]},{"cell_type":"markdown","metadata":{"id":"Q4vNM5IgDtwI"},"source":["## Exercises\n","\n","### Classification\n","\n","1. Design your own examples of labels for binary, multi-class, and multi-label classification. For example, \"A multi-class label is the country a person lives in. A label for this is a 225 element vector with one non-zero element indicating the country the person lives in.\"\n","\n","2. Write out the equations for cross-entropy in multi-class and multi-label settings. \n","\n","### Data\n","\n","1. Use the dimensional reduction methods from our [first chapter](./introduction.ipynb) to plot the molecules here in 2D. Color the points based on their labels. Do you see any patterns?\n","\n","2. Now, use clustering to color the molecules. Use an elbow plot to choose your cluster number.\n","\n","### Assessment\n","\n","1. Repeat the model fitting with L1 and L2 regularization and plot them on a ROC curve. What effect does regularization have on these? Choose a strength of 0.1.\n","\n","2. Could you use leave-one-class-out cross-validation in binary classification? Why or why not?\n","\n","3. We said that class imbalance alone has little effect on model training, as long as the testing distribution matches the training distribution. However, can you make an argument using the bias-variance decomposition about why this may not be true with small dataset size?\n","\n","4. Compute the area under the curve of an ROC curve using numerical trapezoidal integration.\n","\n","### Complete Model\n","\n","Do your best to create a binary-classifier for this dataset with regularization and any other methods we learned from this chapter the previous ones. What is the best area under the curve you can achieve?"]},{"cell_type":"markdown","metadata":{"id":"F7JSY86NDtwI"},"source":["## Cited References\n","\n","```{bibliography}\n",":style: unsrtalpha\n",":filter: docname in docnames\n","```"]}],"metadata":{"celltoolbar":"Tags","colab":{"provenance":[{"file_id":"https://github.com/whitead/dmol-book/blob/master/ml/classification.ipynb","timestamp":1666805089982}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"}},"nbformat":4,"nbformat_minor":0}